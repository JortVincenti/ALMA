============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius#SoftwarepolicySnellius-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please run

python -m bitsandbytes

 and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
bin /home/scur1762/.conda/envs/DSnoT/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda117.so
CUDA SETUP: CUDA runtime path found: /home/scur1762/.conda/envs/DSnoT/lib/libcudart.so.11.0
CUDA SETUP: Highest compute capability among GPUs detected: 8.0
CUDA SETUP: Detected CUDA version 117
CUDA SETUP: Loading binary /home/scur1762/.conda/envs/DSnoT/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...
torch 1.13.1
transformers 4.28.0
accelerate 0.18.0
# of gpus:  1
Model path: haoranxu/ALMA-7B
Model type: None
source and target lang: cs, en
model type: llama
loading llm model haoranxu/ALMA-7B
use device  cuda:0
pruning starts
It's going for DSnoT pruning
Loading calibration data...
Available configs:  ['cs-en']
Loading dataset with source_lang=cs and target_lang=en
Loaded dataset. Sample entry {'translation': {'cs': 'Osmadvacetiletý šéfkuchař nalezen mrtev v obchodě v San Francisku', 'en': '28-Year-Old Chef Found Dead at San Francisco Mall'}}
dataset loading for DSnoT complete
DSnoT pruning layer 0 name self_attn.q_proj
DSnoT pruning layer 0 name self_attn.k_proj
DSnoT pruning layer 0 name self_attn.v_proj
DSnoT pruning layer 0 name self_attn.o_proj
DSnoT pruning layer 0 name mlp.gate_proj
DSnoT pruning layer 0 name mlp.down_proj
DSnoT pruning layer 0 name mlp.up_proj
DSnoT pruning layer 1 name self_attn.q_proj
DSnoT pruning layer 1 name self_attn.k_proj
DSnoT pruning layer 1 name self_attn.v_proj
DSnoT pruning layer 1 name self_attn.o_proj
DSnoT pruning layer 1 name mlp.gate_proj
DSnoT pruning layer 1 name mlp.down_proj
DSnoT pruning layer 1 name mlp.up_proj
DSnoT pruning layer 2 name self_attn.q_proj
DSnoT pruning layer 2 name self_attn.k_proj
DSnoT pruning layer 2 name self_attn.v_proj
DSnoT pruning layer 2 name self_attn.o_proj
DSnoT pruning layer 2 name mlp.gate_proj
DSnoT pruning layer 2 name mlp.down_proj
DSnoT pruning layer 2 name mlp.up_proj
DSnoT pruning layer 3 name self_attn.q_proj
DSnoT pruning layer 3 name self_attn.k_proj
DSnoT pruning layer 3 name self_attn.v_proj
DSnoT pruning layer 3 name self_attn.o_proj
DSnoT pruning layer 3 name mlp.gate_proj
DSnoT pruning layer 3 name mlp.down_proj
DSnoT pruning layer 3 name mlp.up_proj
DSnoT pruning layer 4 name self_attn.q_proj
DSnoT pruning layer 4 name self_attn.k_proj
DSnoT pruning layer 4 name self_attn.v_proj
DSnoT pruning layer 4 name self_attn.o_proj
DSnoT pruning layer 4 name mlp.gate_proj
DSnoT pruning layer 4 name mlp.down_proj
DSnoT pruning layer 4 name mlp.up_proj
DSnoT pruning layer 5 name self_attn.q_proj
DSnoT pruning layer 5 name self_attn.k_proj
DSnoT pruning layer 5 name self_attn.v_proj
DSnoT pruning layer 5 name self_attn.o_proj
DSnoT pruning layer 5 name mlp.gate_proj
DSnoT pruning layer 5 name mlp.down_proj
DSnoT pruning layer 5 name mlp.up_proj
DSnoT pruning layer 6 name self_attn.q_proj
DSnoT pruning layer 6 name self_attn.k_proj
DSnoT pruning layer 6 name self_attn.v_proj
DSnoT pruning layer 6 name self_attn.o_proj
DSnoT pruning layer 6 name mlp.gate_proj
DSnoT pruning layer 6 name mlp.down_proj
DSnoT pruning layer 6 name mlp.up_proj
DSnoT pruning layer 7 name self_attn.q_proj
DSnoT pruning layer 7 name self_attn.k_proj
DSnoT pruning layer 7 name self_attn.v_proj
DSnoT pruning layer 7 name self_attn.o_proj
DSnoT pruning layer 7 name mlp.gate_proj
DSnoT pruning layer 7 name mlp.down_proj
DSnoT pruning layer 7 name mlp.up_proj
DSnoT pruning layer 8 name self_attn.q_proj
DSnoT pruning layer 8 name self_attn.k_proj
DSnoT pruning layer 8 name self_attn.v_proj
DSnoT pruning layer 8 name self_attn.o_proj
DSnoT pruning layer 8 name mlp.gate_proj
DSnoT pruning layer 8 name mlp.down_proj
DSnoT pruning layer 8 name mlp.up_proj
DSnoT pruning layer 9 name self_attn.q_proj
DSnoT pruning layer 9 name self_attn.k_proj
DSnoT pruning layer 9 name self_attn.v_proj
DSnoT pruning layer 9 name self_attn.o_proj
DSnoT pruning layer 9 name mlp.gate_proj
DSnoT pruning layer 9 name mlp.down_proj
DSnoT pruning layer 9 name mlp.up_proj
DSnoT pruning layer 10 name self_attn.q_proj
DSnoT pruning layer 10 name self_attn.k_proj
DSnoT pruning layer 10 name self_attn.v_proj
DSnoT pruning layer 10 name self_attn.o_proj
DSnoT pruning layer 10 name mlp.gate_proj
DSnoT pruning layer 10 name mlp.down_proj
DSnoT pruning layer 10 name mlp.up_proj
DSnoT pruning layer 11 name self_attn.q_proj
DSnoT pruning layer 11 name self_attn.k_proj
DSnoT pruning layer 11 name self_attn.v_proj
DSnoT pruning layer 11 name self_attn.o_proj
DSnoT pruning layer 11 name mlp.gate_proj
DSnoT pruning layer 11 name mlp.down_proj
DSnoT pruning layer 11 name mlp.up_proj
DSnoT pruning layer 12 name self_attn.q_proj
DSnoT pruning layer 12 name self_attn.k_proj
DSnoT pruning layer 12 name self_attn.v_proj
DSnoT pruning layer 12 name self_attn.o_proj
DSnoT pruning layer 12 name mlp.gate_proj
DSnoT pruning layer 12 name mlp.down_proj
DSnoT pruning layer 12 name mlp.up_proj
DSnoT pruning layer 13 name self_attn.q_proj
DSnoT pruning layer 13 name self_attn.k_proj
DSnoT pruning layer 13 name self_attn.v_proj
DSnoT pruning layer 13 name self_attn.o_proj
DSnoT pruning layer 13 name mlp.gate_proj
DSnoT pruning layer 13 name mlp.down_proj
DSnoT pruning layer 13 name mlp.up_proj
DSnoT pruning layer 14 name self_attn.q_proj
DSnoT pruning layer 14 name self_attn.k_proj
DSnoT pruning layer 14 name self_attn.v_proj
DSnoT pruning layer 14 name self_attn.o_proj
DSnoT pruning layer 14 name mlp.gate_proj
DSnoT pruning layer 14 name mlp.down_proj
DSnoT pruning layer 14 name mlp.up_proj
DSnoT pruning layer 15 name self_attn.q_proj
DSnoT pruning layer 15 name self_attn.k_proj
DSnoT pruning layer 15 name self_attn.v_proj
DSnoT pruning layer 15 name self_attn.o_proj
DSnoT pruning layer 15 name mlp.gate_proj
DSnoT pruning layer 15 name mlp.down_proj
DSnoT pruning layer 15 name mlp.up_proj
DSnoT pruning layer 16 name self_attn.q_proj
DSnoT pruning layer 16 name self_attn.k_proj
DSnoT pruning layer 16 name self_attn.v_proj
DSnoT pruning layer 16 name self_attn.o_proj
DSnoT pruning layer 16 name mlp.gate_proj
DSnoT pruning layer 16 name mlp.down_proj
DSnoT pruning layer 16 name mlp.up_proj
DSnoT pruning layer 17 name self_attn.q_proj
DSnoT pruning layer 17 name self_attn.k_proj
DSnoT pruning layer 17 name self_attn.v_proj
DSnoT pruning layer 17 name self_attn.o_proj
DSnoT pruning layer 17 name mlp.gate_proj
DSnoT pruning layer 17 name mlp.down_proj
DSnoT pruning layer 17 name mlp.up_proj
DSnoT pruning layer 18 name self_attn.q_proj
DSnoT pruning layer 18 name self_attn.k_proj
DSnoT pruning layer 18 name self_attn.v_proj
DSnoT pruning layer 18 name self_attn.o_proj
DSnoT pruning layer 18 name mlp.gate_proj
DSnoT pruning layer 18 name mlp.down_proj
DSnoT pruning layer 18 name mlp.up_proj
DSnoT pruning layer 19 name self_attn.q_proj
DSnoT pruning layer 19 name self_attn.k_proj
DSnoT pruning layer 19 name self_attn.v_proj
DSnoT pruning layer 19 name self_attn.o_proj
DSnoT pruning layer 19 name mlp.gate_proj
DSnoT pruning layer 19 name mlp.down_proj
DSnoT pruning layer 19 name mlp.up_proj
DSnoT pruning layer 20 name self_attn.q_proj
DSnoT pruning layer 20 name self_attn.k_proj
DSnoT pruning layer 20 name self_attn.v_proj
DSnoT pruning layer 20 name self_attn.o_proj
DSnoT pruning layer 20 name mlp.gate_proj
DSnoT pruning layer 20 name mlp.down_proj
DSnoT pruning layer 20 name mlp.up_proj
DSnoT pruning layer 21 name self_attn.q_proj
DSnoT pruning layer 21 name self_attn.k_proj
DSnoT pruning layer 21 name self_attn.v_proj
DSnoT pruning layer 21 name self_attn.o_proj
DSnoT pruning layer 21 name mlp.gate_proj
DSnoT pruning layer 21 name mlp.down_proj
DSnoT pruning layer 21 name mlp.up_proj
DSnoT pruning layer 22 name self_attn.q_proj
DSnoT pruning layer 22 name self_attn.k_proj
DSnoT pruning layer 22 name self_attn.v_proj
DSnoT pruning layer 22 name self_attn.o_proj
DSnoT pruning layer 22 name mlp.gate_proj
DSnoT pruning layer 22 name mlp.down_proj
DSnoT pruning layer 22 name mlp.up_proj
DSnoT pruning layer 23 name self_attn.q_proj
DSnoT pruning layer 23 name self_attn.k_proj
DSnoT pruning layer 23 name self_attn.v_proj
DSnoT pruning layer 23 name self_attn.o_proj
DSnoT pruning layer 23 name mlp.gate_proj
DSnoT pruning layer 23 name mlp.down_proj
DSnoT pruning layer 23 name mlp.up_proj
DSnoT pruning layer 24 name self_attn.q_proj
DSnoT pruning layer 24 name self_attn.k_proj
DSnoT pruning layer 24 name self_attn.v_proj
DSnoT pruning layer 24 name self_attn.o_proj
DSnoT pruning layer 24 name mlp.gate_proj
DSnoT pruning layer 24 name mlp.down_proj
DSnoT pruning layer 24 name mlp.up_proj
DSnoT pruning layer 25 name self_attn.q_proj
DSnoT pruning layer 25 name self_attn.k_proj
DSnoT pruning layer 25 name self_attn.v_proj
DSnoT pruning layer 25 name self_attn.o_proj
DSnoT pruning layer 25 name mlp.gate_proj
DSnoT pruning layer 25 name mlp.down_proj

Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]
Loading checkpoint shards:  33%|███▎      | 1/3 [00:04<00:09,  4.54s/it]
Loading checkpoint shards:  67%|██████▋   | 2/3 [00:08<00:04,  4.07s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.46s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.67s/it]
DSnoT pruning layer 25 name mlp.up_proj
DSnoT pruning layer 26 name self_attn.q_proj
DSnoT pruning layer 26 name self_attn.k_proj
DSnoT pruning layer 26 name self_attn.v_proj
DSnoT pruning layer 26 name self_attn.o_proj
DSnoT pruning layer 26 name mlp.gate_proj
DSnoT pruning layer 26 name mlp.down_proj
DSnoT pruning layer 26 name mlp.up_proj
DSnoT pruning layer 27 name self_attn.q_proj
DSnoT pruning layer 27 name self_attn.k_proj
DSnoT pruning layer 27 name self_attn.v_proj
DSnoT pruning layer 27 name self_attn.o_proj
DSnoT pruning layer 27 name mlp.gate_proj
DSnoT pruning layer 27 name mlp.down_proj
DSnoT pruning layer 27 name mlp.up_proj
DSnoT pruning layer 28 name self_attn.q_proj
DSnoT pruning layer 28 name self_attn.k_proj
DSnoT pruning layer 28 name self_attn.v_proj
DSnoT pruning layer 28 name self_attn.o_proj
DSnoT pruning layer 28 name mlp.gate_proj
DSnoT pruning layer 28 name mlp.down_proj
DSnoT pruning layer 28 name mlp.up_proj
DSnoT pruning layer 29 name self_attn.q_proj
DSnoT pruning layer 29 name self_attn.k_proj
DSnoT pruning layer 29 name self_attn.v_proj
DSnoT pruning layer 29 name self_attn.o_proj
DSnoT pruning layer 29 name mlp.gate_proj
DSnoT pruning layer 29 name mlp.down_proj
DSnoT pruning layer 29 name mlp.up_proj
DSnoT pruning layer 30 name self_attn.q_proj
DSnoT pruning layer 30 name self_attn.k_proj
DSnoT pruning layer 30 name self_attn.v_proj
DSnoT pruning layer 30 name self_attn.o_proj
DSnoT pruning layer 30 name mlp.gate_proj
DSnoT pruning layer 30 name mlp.down_proj
DSnoT pruning layer 30 name mlp.up_proj
DSnoT pruning layer 31 name self_attn.q_proj
DSnoT pruning layer 31 name self_attn.k_proj
DSnoT pruning layer 31 name self_attn.v_proj
DSnoT pruning layer 31 name self_attn.o_proj
DSnoT pruning layer 31 name mlp.gate_proj
DSnoT pruning layer 31 name mlp.down_proj
DSnoT pruning layer 31 name mlp.up_proj
******************************
layer 0 sparsity 0.500000
layer 1 sparsity 0.500000
layer 2 sparsity 0.500000
layer 3 sparsity 0.500000
layer 4 sparsity 0.500000
layer 5 sparsity 0.500000
layer 6 sparsity 0.500000
layer 7 sparsity 0.500000
layer 8 sparsity 0.500000
layer 9 sparsity 0.500000
layer 10 sparsity 0.500000
layer 11 sparsity 0.500000
layer 12 sparsity 0.500000
layer 13 sparsity 0.500000
layer 14 sparsity 0.500000
layer 15 sparsity 0.500000
layer 16 sparsity 0.500000
layer 17 sparsity 0.500000
layer 18 sparsity 0.500000
layer 19 sparsity 0.500000
layer 20 sparsity 0.500000
layer 21 sparsity 0.500000
layer 22 sparsity 0.500000
layer 23 sparsity 0.500000
layer 24 sparsity 0.500000
layer 25 sparsity 0.500000
layer 26 sparsity 0.500000
layer 27 sparsity 0.500000
layer 28 sparsity 0.500000
layer 29 sparsity 0.500000
layer 30 sparsity 0.500000
layer 31 sparsity 0.500000
sparsity sanity check 0.5000
******************************
came in here
should have saved now
length of dataframes 'path' lang direction: 1448
length of test_df: 1448
Index(['cs-en'], dtype='object')

Processing Batches:   0%|          | 0/181 [00:00<?, ?it/s]
Processing Batches:   1%|          | 1/181 [00:02<07:31,  2.51s/it]
Processing Batches:   1%|          | 2/181 [00:04<06:17,  2.11s/it]
Processing Batches:   2%|▏         | 3/181 [00:06<06:36,  2.23s/it]
Processing Batches:   2%|▏         | 4/181 [00:09<07:35,  2.57s/it]
Processing Batches:   3%|▎         | 5/181 [00:13<09:04,  3.09s/it]
Processing Batches:   3%|▎         | 6/181 [00:17<09:40,  3.32s/it]
Processing Batches:   4%|▍         | 7/181 [00:20<08:55,  3.08s/it]
Processing Batches:   4%|▍         | 8/181 [00:44<28:21,  9.83s/it]
Processing Batches:   5%|▍         | 9/181 [00:46<21:38,  7.55s/it]
Processing Batches:   6%|▌         | 10/181 [00:50<17:57,  6.30s/it]
Processing Batches:   6%|▌         | 11/181 [01:12<31:47, 11.22s/it]
Processing Batches:   7%|▋         | 12/181 [01:16<25:22,  9.01s/it]
Processing Batches:   7%|▋         | 13/181 [01:18<19:22,  6.92s/it]
Processing Batches:   8%|▊         | 14/181 [01:21<15:39,  5.62s/it]
Processing Batches:   8%|▊         | 15/181 [01:41<27:50, 10.06s/it]
Processing Batches:   9%|▉         | 16/181 [02:01<35:52, 13.05s/it]
Processing Batches:   9%|▉         | 17/181 [02:04<27:24, 10.02s/it]
Processing Batches:  10%|▉         | 18/181 [02:08<22:03,  8.12s/it]
Processing Batches:  10%|█         | 19/181 [02:11<17:39,  6.54s/it]
Processing Batches:  11%|█         | 20/181 [02:13<14:06,  5.26s/it]
Processing Batches:  12%|█▏        | 21/181 [02:15<11:36,  4.35s/it]
Processing Batches:  12%|█▏        | 22/181 [02:18<10:24,  3.93s/it]
Processing Batches:  13%|█▎        | 23/181 [02:22<10:17,  3.91s/it]
Processing Batches:  13%|█▎        | 24/181 [02:25<09:17,  3.55s/it]
Processing Batches:  14%|█▍        | 25/181 [02:45<21:43,  8.36s/it]
Processing Batches:  14%|█▍        | 26/181 [02:47<17:15,  6.68s/it]
Processing Batches:  15%|█▍        | 27/181 [02:50<14:04,  5.48s/it]
Processing Batches:  15%|█▌        | 28/181 [03:15<28:44, 11.27s/it]
Processing Batches:  16%|█▌        | 29/181 [03:18<22:23,  8.84s/it]
Processing Batches:  17%|█▋        | 30/181 [03:21<18:13,  7.24s/it]
Processing Batches:  17%|█▋        | 31/181 [03:24<14:29,  5.80s/it]
Processing Batches:  18%|█▊        | 32/181 [03:26<11:41,  4.71s/it]
Processing Batches:  18%|█▊        | 33/181 [03:28<09:39,  3.92s/it]
Processing Batches:  19%|█▉        | 34/181 [03:31<08:29,  3.46s/it]
Processing Batches:  19%|█▉        | 35/181 [03:33<07:47,  3.20s/it]
Processing Batches:  20%|█▉        | 36/181 [03:36<07:45,  3.21s/it]
Processing Batches:  20%|██        | 37/181 [03:56<19:43,  8.22s/it]
Processing Batches:  21%|██        | 38/181 [04:00<16:44,  7.03s/it]
Processing Batches:  22%|██▏       | 39/181 [04:04<14:23,  6.08s/it]
Processing Batches:  22%|██▏       | 40/181 [04:07<11:54,  5.07s/it]
Processing Batches:  23%|██▎       | 41/181 [04:10<10:29,  4.50s/it]
Processing Batches:  23%|██▎       | 42/181 [04:14<09:42,  4.19s/it]
Processing Batches:  24%|██▍       | 43/181 [04:35<21:44,  9.45s/it]
Processing Batches:  24%|██▍       | 44/181 [04:55<28:40, 12.55s/it]
Processing Batches:  25%|██▍       | 45/181 [05:16<34:23, 15.17s/it]
Processing Batches:  25%|██▌       | 46/181 [05:20<26:26, 11.76s/it]
Processing Batches:  26%|██▌       | 47/181 [05:42<32:53, 14.73s/it]
Processing Batches:  27%|██▋       | 48/181 [05:45<24:54, 11.24s/it]
Processing Batches:  27%|██▋       | 49/181 [06:04<30:05, 13.68s/it]
Processing Batches:  28%|██▊       | 50/181 [06:25<34:09, 15.64s/it]
Processing Batches:  28%|██▊       | 51/181 [06:27<25:16, 11.66s/it]
Processing Batches:  29%|██▊       | 52/181 [06:46<30:03, 13.98s/it]
Processing Batches:  29%|██▉       | 53/181 [06:48<22:07, 10.37s/it]
Processing Batches:  30%|██▉       | 54/181 [06:51<16:53,  7.98s/it]
Processing Batches:  30%|███       | 55/181 [07:09<23:22, 11.13s/it]
Processing Batches:  31%|███       | 56/181 [07:30<29:00, 13.92s/it]
Processing Batches:  31%|███▏      | 57/181 [07:49<32:19, 15.64s/it]
Processing Batches:  32%|███▏      | 58/181 [07:54<25:04, 12.23s/it]
Processing Batches:  33%|███▎      | 59/181 [07:59<20:41, 10.18s/it]
Processing Batches:  33%|███▎      | 60/181 [08:02<16:16,  8.07s/it]
Processing Batches:  34%|███▎      | 61/181 [08:05<13:08,  6.57s/it]
Processing Batches:  34%|███▍      | 62/181 [08:09<11:10,  5.64s/it]
Processing Batches:  35%|███▍      | 63/181 [08:28<19:05,  9.71s/it]
Processing Batches:  35%|███▌      | 64/181 [08:49<25:24, 13.03s/it]
Processing Batches:  36%|███▌      | 65/181 [08:50<18:17,  9.46s/it]
Processing Batches:  36%|███▋      | 66/181 [09:10<24:29, 12.78s/it]
Processing Batches:  37%|███▋      | 67/181 [09:33<30:04, 15.83s/it]
Processing Batches:  38%|███▊      | 68/181 [09:37<22:47, 12.10s/it]
Processing Batches:  38%|███▊      | 69/181 [09:40<17:45,  9.51s/it]
Processing Batches:  39%|███▊      | 70/181 [09:43<13:57,  7.54s/it]
Processing Batches:  39%|███▉      | 71/181 [09:46<11:20,  6.18s/it]
Processing Batches:  40%|███▉      | 72/181 [09:49<09:22,  5.16s/it]
Processing Batches:  40%|████      | 73/181 [09:51<07:53,  4.39s/it]
Processing Batches:  41%|████      | 74/181 [09:53<06:34,  3.69s/it]
Processing Batches:  41%|████▏     | 75/181 [09:57<06:33,  3.71s/it]
Processing Batches:  42%|████▏     | 76/181 [10:00<06:09,  3.52s/it]
Processing Batches:  43%|████▎     | 77/181 [10:03<05:46,  3.33s/it]
Processing Batches:  43%|████▎     | 78/181 [10:05<05:08,  3.00s/it]
Processing Batches:  44%|████▎     | 79/181 [10:07<04:34,  2.69s/it]
Processing Batches:  44%|████▍     | 80/181 [10:10<04:27,  2.65s/it]
Processing Batches:  45%|████▍     | 81/181 [10:13<04:21,  2.62s/it]
Processing Batches:  45%|████▌     | 82/181 [10:16<04:38,  2.81s/it]
Processing Batches:  46%|████▌     | 83/181 [10:19<04:35,  2.81s/it]
Processing Batches:  46%|████▋     | 84/181 [10:20<04:06,  2.54s/it]
Processing Batches:  47%|████▋     | 85/181 [10:23<04:08,  2.59s/it]
Processing Batches:  48%|████▊     | 86/181 [10:26<04:19,  2.73s/it]
Processing Batches:  48%|████▊     | 87/181 [10:29<04:06,  2.63s/it]
Processing Batches:  49%|████▊     | 88/181 [10:31<03:54,  2.52s/it]
Processing Batches:  49%|████▉     | 89/181 [10:33<03:38,  2.38s/it]
Processing Batches:  50%|████▉     | 90/181 [10:35<03:37,  2.40s/it]
Processing Batches:  50%|█████     | 91/181 [10:40<04:22,  2.92s/it]
Processing Batches:  51%|█████     | 92/181 [10:42<04:16,  2.88s/it]
Processing Batches:  51%|█████▏    | 93/181 [10:45<03:59,  2.72s/it]
Processing Batches:  52%|█████▏    | 94/181 [10:47<03:46,  2.60s/it]
Processing Batches:  52%|█████▏    | 95/181 [10:49<03:28,  2.43s/it]
Processing Batches:  53%|█████▎    | 96/181 [10:52<03:53,  2.75s/it]
Processing Batches:  54%|█████▎    | 97/181 [10:58<05:09,  3.69s/it]
Processing Batches:  54%|█████▍    | 98/181 [11:01<04:47,  3.46s/it]
Processing Batches:  55%|█████▍    | 99/181 [11:19<10:43,  7.85s/it]
Processing Batches:  55%|█████▌    | 100/181 [11:39<15:14, 11.29s/it]
Processing Batches:  56%|█████▌    | 101/181 [11:42<11:48,  8.86s/it]
Processing Batches:  56%|█████▋    | 102/181 [11:44<09:05,  6.91s/it]
Processing Batches:  57%|█████▋    | 103/181 [12:04<14:06, 10.86s/it]
Processing Batches:  57%|█████▋    | 104/181 [12:06<10:30,  8.19s/it]
Processing Batches:  58%|█████▊    | 105/181 [12:14<10:00,  7.90s/it]
Processing Batches:  59%|█████▊    | 106/181 [12:31<13:27, 10.77s/it]
Processing Batches:  59%|█████▉    | 107/181 [12:53<17:37, 14.29s/it]
Processing Batches:  60%|█████▉    | 108/181 [12:59<14:12, 11.68s/it]
Processing Batches:  60%|██████    | 109/181 [13:01<10:39,  8.88s/it]
Processing Batches:  61%|██████    | 110/181 [13:04<08:25,  7.11s/it]
Processing Batches:  61%|██████▏   | 111/181 [13:09<07:17,  6.25s/it]
Processing Batches:  62%|██████▏   | 112/181 [13:13<06:29,  5.64s/it]
Processing Batches:  62%|██████▏   | 113/181 [13:15<05:17,  4.68s/it]
Processing Batches:  63%|██████▎   | 114/181 [13:19<04:57,  4.45s/it]
Processing Batches:  64%|██████▎   | 115/181 [13:21<04:01,  3.66s/it]
Processing Batches:  64%|██████▍   | 116/181 [13:24<03:36,  3.33s/it]
Processing Batches:  65%|██████▍   | 117/181 [13:26<03:14,  3.05s/it]
Processing Batches:  65%|██████▌   | 118/181 [13:30<03:26,  3.28s/it]
Processing Batches:  66%|██████▌   | 119/181 [13:32<03:10,  3.07s/it]
Processing Batches:  66%|██████▋   | 120/181 [13:35<02:57,  2.91s/it]
Processing Batches:  67%|██████▋   | 121/181 [13:55<08:10,  8.18s/it]
Processing Batches:  67%|██████▋   | 122/181 [13:57<06:08,  6.24s/it]
Processing Batches:  68%|██████▊   | 123/181 [14:00<05:08,  5.32s/it]
Processing Batches:  69%|██████▊   | 124/181 [14:04<04:42,  4.96s/it]
Processing Batches:  69%|██████▉   | 125/181 [14:07<03:58,  4.27s/it]
Processing Batches:  70%|██████▉   | 126/181 [14:10<03:35,  3.91s/it]
Processing Batches:  70%|███████   | 127/181 [14:27<06:58,  7.76s/it]
Processing Batches:  71%|███████   | 128/181 [14:48<10:16, 11.63s/it]
Processing Batches:  71%|███████▏  | 129/181 [14:50<07:38,  8.81s/it]
Processing Batches:  72%|███████▏  | 130/181 [14:52<05:45,  6.77s/it]
Processing Batches:  72%|███████▏  | 131/181 [14:54<04:26,  5.34s/it]
Processing Batches:  73%|███████▎  | 132/181 [14:57<03:43,  4.57s/it]
Processing Batches:  73%|███████▎  | 133/181 [14:59<03:14,  4.06s/it]
Processing Batches:  74%|███████▍  | 134/181 [15:02<02:45,  3.53s/it]
Processing Batches:  75%|███████▍  | 135/181 [15:05<02:37,  3.43s/it]
Processing Batches:  75%|███████▌  | 136/181 [15:08<02:23,  3.19s/it]
Processing Batches:  76%|███████▌  | 137/181 [15:11<02:18,  3.16s/it]
Processing Batches:  76%|███████▌  | 138/181 [15:13<02:05,  2.92s/it]
Processing Batches:  77%|███████▋  | 139/181 [15:15<01:52,  2.69s/it]
Processing Batches:  77%|███████▋  | 140/181 [15:18<01:54,  2.80s/it]
Processing Batches:  78%|███████▊  | 141/181 [15:22<02:01,  3.05s/it]
Processing Batches:  78%|███████▊  | 142/181 [15:24<01:44,  2.67s/it]
Processing Batches:  79%|███████▉  | 143/181 [15:26<01:35,  2.51s/it]
Processing Batches:  80%|███████▉  | 144/181 [15:28<01:34,  2.56s/it]
Processing Batches:  80%|████████  | 145/181 [15:31<01:32,  2.58s/it]
Processing Batches:  81%|████████  | 146/181 [15:34<01:34,  2.70s/it]
Processing Batches:  81%|████████  | 147/181 [15:52<04:10,  7.36s/it]
Processing Batches:  82%|████████▏ | 148/181 [16:12<06:09, 11.19s/it]
Processing Batches:  82%|████████▏ | 149/181 [16:33<07:32, 14.14s/it]
Processing Batches:  83%|████████▎ | 150/181 [16:55<08:28, 16.40s/it]
Processing Batches:  83%|████████▎ | 151/181 [16:59<06:22, 12.76s/it]
Processing Batches:  84%|████████▍ | 152/181 [17:02<04:42,  9.73s/it]
Processing Batches:  85%|████████▍ | 153/181 [17:04<03:29,  7.47s/it]
Processing Batches:  85%|████████▌ | 154/181 [17:07<02:44,  6.09s/it]
Processing Batches:  86%|████████▌ | 155/181 [17:10<02:13,  5.12s/it]
Processing Batches:  86%|████████▌ | 156/181 [17:12<01:48,  4.34s/it]
Processing Batches:  87%|████████▋ | 157/181 [17:15<01:31,  3.81s/it]
Processing Batches:  87%|████████▋ | 158/181 [17:36<03:23,  8.84s/it]
Processing Batches:  88%|████████▊ | 159/181 [17:39<02:36,  7.11s/it]
Processing Batches:  88%|████████▊ | 160/181 [17:42<02:04,  5.92s/it]
Processing Batches:  89%|████████▉ | 161/181 [17:45<01:39,  4.97s/it]
Processing Batches:  90%|████████▉ | 162/181 [17:47<01:18,  4.14s/it]
Processing Batches:  90%|█████████ | 163/181 [17:48<01:01,  3.41s/it]
Processing Batches:  91%|█████████ | 164/181 [18:11<02:33,  9.04s/it]
Processing Batches:  91%|█████████ | 165/181 [18:16<02:08,  8.00s/it]
Processing Batches:  92%|█████████▏| 166/181 [18:19<01:35,  6.38s/it]
Processing Batches:  92%|█████████▏| 167/181 [18:23<01:18,  5.62s/it]
Processing Batches:  93%|█████████▎| 168/181 [18:27<01:06,  5.11s/it]
Processing Batches:  93%|█████████▎| 169/181 [18:33<01:07,  5.59s/it]
Processing Batches:  94%|█████████▍| 170/181 [18:38<00:57,  5.21s/it]
Processing Batches:  94%|█████████▍| 171/181 [18:40<00:42,  4.25s/it]
Processing Batches:  95%|█████████▌| 172/181 [18:59<01:18,  8.77s/it]
Processing Batches:  96%|█████████▌| 173/181 [19:01<00:52,  6.61s/it]
Processing Batches:  96%|█████████▌| 174/181 [19:02<00:36,  5.20s/it]
Processing Batches:  97%|█████████▋| 175/181 [19:05<00:25,  4.27s/it]
Processing Batches:  97%|█████████▋| 176/181 [19:08<00:20,  4.05s/it]
Processing Batches:  98%|█████████▊| 177/181 [19:11<00:14,  3.69s/it]
Processing Batches:  98%|█████████▊| 178/181 [19:13<00:09,  3.21s/it]
Processing Batches:  99%|█████████▉| 179/181 [19:16<00:06,  3.22s/it]
Processing Batches:  99%|█████████▉| 180/181 [19:19<00:02,  2.97s/it]
Processing Batches: 100%|██████████| 181/181 [19:38<00:00,  7.82s/it]
Processing Batches: 182it [19:40,  6.15s/it]                         
Processing Batches: 182it [19:40,  6.49s/it]
****************************************************************************************************
Evaluation Results:
Time taken for generation: 1175.32 seconds
Average generation time: 0.8116833233372283 seconds
BLEU score: 21.98540472854384
Average ROUGE-1 F1 score: 0.5802068744681399
Average ROUGE-2 F1 score: 0.3458209079769864
Average ROUGE-L F1 score: 0.5353859242256926
****************************************************************************************************

ppl on WMT22-Test: 21.98540472854384

model: haoranxu/ALMA-7B
prune_method: DSnoT
without_DSnoT: False
initial_method: wanda
skip_layer mlp, skip_sub_layer no_skip
max_cycle_time: 50, update_threshold: 0.1
pow_of_var_pruning:1, pow_of_var_regrowing:1.0
without_same_sign:True
sparse pattern: unstructured
sample: 128
sparsity sanity check 0.5000, ppl: 21.98540472854384



JOB STATISTICS
==============
Job ID: 8102170
Cluster: snellius
User/Group: scur1762/scur1762
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 06:35:24 core-walltime
Job Wall-clock time: 00:21:58
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 120.00 GB (120.00 GB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
