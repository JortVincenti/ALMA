Traceback (most recent call last):
  File "/gpfs/home3/scur1746/ALMA/.env/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1764, in _get_module
  File "/gpfs/home3/scur1746/ALMA/.env/lib/python3.11/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1140, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'transformers.models.llama.tokenization_llama'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/home3/scur1746/ALMA/eval.py", line 4, in <module>
    from transformers import AutoModelForCausalLM, LlamaTokenizer
  File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
  File "/gpfs/home3/scur1746/ALMA/.env/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1755, in __getattr__
  File "/gpfs/home3/scur1746/ALMA/.env/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1754, in __getattr__
  File "/gpfs/home3/scur1746/ALMA/.env/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1766, in _get_module
RuntimeError: Failed to import transformers.models.llama.tokenization_llama because of the following error (look up to see its traceback):
No module named 'transformers.models.llama.tokenization_llama'

JOB STATISTICS
==============
Job ID: 8109581
Cluster: snellius
User/Group: scur1746/scur1746
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 00:05:42 core-walltime
Job Wall-clock time: 00:00:19
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 120.00 GB (120.00 GB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
